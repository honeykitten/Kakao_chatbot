import urllib
from urllib.request import urlopen, Request

from bs4 import BeautifulSoup
from flask import Flask, request, jsonify

app = Flask(__name__)


@app.route('/weather', methods=['POST'])  # ë¯¸ì„¸ë¨¼ì§€ ìŠ¤í‚¬ë¡œ ì—°ê²°ëœ ê²½ë¡œ
def weather():
    req = request.get_json()
    params = req['action']['detailParams']
    if not params.get('sys_location'):  # ì…ë ¥ í…ìŠ¤íŠ¸ì— ì§€ì—­ì´ ì—†ì„ ê²½ìš°ëŠ” ë°”ë¡œ ê²½ê³  ë©”ì‹œì§€ ì „ì†¡
        res = {
            "version": "2.0",
            "template": {
                "outputs": [
                    {
                        "simpleText": {
                            "text": "ì§€ì—­ì„ ì…ë ¥í•˜ì„¸ìš”.(ì˜ˆì‹œ: ì‚¼í‰ë™ ë¯¸ì„¸ë¨¼ì§€, ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ ë¯¸ì„¸ë¨¼ì§€, ì¸ì²œê´‘ì—­ì‹œ ìƒë™ ë¯¸ì„¸ë¨¼ì§€)"
                        }
                    }
                ]
            }
        }

        return jsonify(res)

#    if params.get('sys_location'):  # ì§€ì—­ì„ ì„¸ë¶€ ì£¼ì†Œê¹Œì§€ ë°›ì„ ìˆ˜ ìˆê²Œ 3ê°œë¡œ ë‚˜ëˆ”
#        location = params['sys_location']['value']
#    if params.get('sys_location1'):
#        location += f"+{params['sys_location1']['value']}"  # python 3.6 ì´ìƒ f string ìŠ¤íƒ€ì¼ë¡œ ì‹¤í–‰
#        location += f"+{params['sys_location2']['value']}"

#    location_encoding = urllib.parse.quote(location + '+ë‚ ì”¨')  # url ì¸ì½”ë”©
#    url = f'https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query={location_encoding}'

    if 'sys_location' in params.keys():  # ì§€ì—­ì„ ì‹œ êµ¬ ë™ìœ¼ë¡œ 3ê°œê¹Œì§€ ì…ë ¥ì„ ë°›ì„ ìˆ˜ ìˆì–´ì„œ ìˆœì„œëŒ€ë¡œ locationì— ì €ì¥
        location = params['sys_location']['value']
    if 'sys_location1' in params.keys():
        location += ' + ' + params['sys_location1']['value']
    if 'sys_location2' in params.keys():
        location += ' + ' + params['sys_location2']['value']

    location_encoding = urllib.parse.quote(location + '+ë‚ ì”¨')  # url ì¸ì½”ë”©
    url = 'https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=%s' % (location_encoding)

    req = Request(url)
    page = urlopen(req)
    html = page.read()
    soup = BeautifulSoup(html, 'html.parser')

    if soup.find('span', {'class': 'btn_select'}) == None:  # ê°™ì€ ì´ë¦„ ì²˜ë¦¬
        region = soup.find('li', {'role': 'option'}).text
    else:
        region = soup.find('span', {'class': 'btn_select'}).text

    if params.get('sys_date_period'):
        weekly_weather = soup.find_all('li', {'class': 'date_info today'})

    elif not params.get('sys_date') or 'today' in params['sys_date']['value']:  # ì˜¤ëŠ˜ ë¯¸ì„¸ë¨¼ì§€ ê°€ì ¸ì˜¤ê¸°
        info = soup.find('p', {'class': 'cast_txt'}).text
        temp_rain_info = soup.find_all('dd', {'class': 'weather_item _dotWrapper'})
        temp = temp_rain_info[0].text.replace('ë„', '')
        rain_rate = temp_rain_info[8].text
        sub_info = soup.find_all('dd')
        finedust = sub_info[2].text.replace('ã/ã¥', 'ã/ã¥ ')
        Ultrafinedust = sub_info[3].text.replace('ã/ã¥', 'ã/ã¥ ')

        print(len(finedust))
        if float(finedust[0:2]) > 31:
            dust_status = "ì–‘ì§‘ì‚¬ì˜ ì½”ë©˜íŠ¸: ë§ˆìŠ¤í¬ ì°©ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤!ğŸ˜·"
        else:
            dust_status = "ì–‘ì§‘ì‚¬ì˜ ì½”ë©˜íŠ¸: ë¯¸ì„¸ë¨¼ì§€ê°€ ë‚®ìŠµë‹ˆë‹¤. ë§ˆìŠ¤í¬ ì°©ìš©ì„ í•˜ì§€ ì•Šìœ¼ì…”ë„ ë˜ê² ë„¤ìš”.ğŸ˜Š"

        answer = f"""\
{region} í˜„ì¬ ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ì…ë‹ˆë‹¤.
ë¯¸ì„¸ë¨¼ì§€ : {finedust}
ì´ˆë¯¸ì„¸ë¨¼ì§€ : {Ultrafinedust}

{dust_status}

ì „ ë‹¨ê³„ë¡œ ëŒì•„ê°€ê³  ì‹¶ìœ¼ì‹œë©´ "ã…ã…‡"ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”! ğŸ‘ˆ"""

    # ì¼ë°˜ í…ìŠ¤íŠ¸í˜• ì‘ë‹µìš© ë©”ì‹œì§€
    res = {
        "version": "2.0",
        "template": {
            "outputs": [
                {
                    "simpleText": {
                        "text": answer
                    }
                }
            ]
        }
    }

    return jsonify(res)

@app.route('/vancouvertime', methods=['POST']) # ìºë‚˜ë‹¤ ë²¤ì¿ ë²„ ì‹œê°„ ì •ë³´ ë¸”ëŸ­ì— ìŠ¤í‚¬ë¡œ ì—°ê²°ëœ ê²½ë¡œ

def vancouvertime():
   req = request.get_json()

   location2 = req["action"]["detailParams"]

   url = 'https://search.yahoo.com/search?p=vancouver+time&fr=yfp-t&ei=UTF-8&fp=1'

   #enc_loc = urllib.parse.quote(location2 + '+ ì‹œê°„')
   #el = str(enc_loc)

   #url = 'https://search.yahoo.com/search?p='
   #url = url + el
   #url = url + '&fr=yfp-t&ei=UTF-8&fp=1'

   req = Request(url)
   page = urlopen(req)
   html = page.read()
   soup = BeautifulSoup(html, 'html.parser')

   temp = soup.find('div', class_='compTitle d-ib mt-16 va-mid')
   temp_s = temp.find('h3', class_='title')
   temp_a = temp_s.find('span', class_='fc-inkwell fz-32 lh-40 primaryCityTime').text

   ampm = str(temp_a[6:8])
   hour = str(temp_a[0:2])
   minute = str(temp_a[3:5])


   global answer
   answer = ''

   if ampm == 'AM':
       answer += 'í˜„ì¬ ìºë‚˜ë‹¤ ë²¤ì¿ ë²„ì˜ ì‹œê°„ì€ ì˜¤ì „ ' + hour + 'ì‹œ ' + minute + 'ë¶„ì…ë‹ˆë‹¤.' + '\n' + '\n'
       if int(hour) < 6:
           answer += 'ì–‘ì§‘ì‚¬ì˜ ì½”ë©˜íŠ¸: ì§€ê¸ˆì€ ìëŠ” ì‹œê°„ì´ì—ìš”! ğŸŒ™'
       else:
           answer += 'ì–‘ì§‘ì‚¬ì˜ ì½”ë©˜íŠ¸: í•˜ë£¨ ì—…ë¬´ê°€ ì‹œì‘ë˜ëŠ” ìƒì¾Œí•œ ì•„ì¹¨ì…ë‹ˆë‹¤. â˜€'
       answer += '\n' + '\n'
       answer += 'ì „ ë‹¨ê³„ë¡œ ëŒì•„ê°€ê³  ì‹¶ìœ¼ì‹œë©´ "ã…ã…‡"ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”! ğŸ‘ˆ'

   else:
       answer += 'í˜„ì¬ ìºë‚˜ë‹¤ ë²¤ì¿ ë²„ì˜ ì‹œê°„ì€ ì˜¤í›„ ' + hour + 'ì‹œ ' + minute + 'ë¶„ì…ë‹ˆë‹¤.' + '\n' + '\n'
       if int(hour) < 19:
           answer += 'ì–‘ì§‘ì‚¬ì˜ ì½”ë©˜íŠ¸: ì ì‹¬ì„ ë¨¹ê³  ì—…ë¬´ê°€ ì¡°ê¸ˆì”© ë§ˆë¬´ë¦¬ë˜ëŠ” ì˜¤í›„ì…ë‹ˆë‹¤. â˜€'
       else:
           answer += 'ì–‘ì§‘ì‚¬ì˜ ì½”ë©˜íŠ¸: ë°¤ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. í•˜ë£¨ ì¼ê³¼ê°€ ê±°ì˜ ë§ˆë¬´ë¦¬ë˜ëŠ” ì‹œê°„ì…ë‹ˆë‹¤. ğŸŒ™'
       answer += '\n' + '\n'
       answer += 'ì „ ë‹¨ê³„ë¡œ ëŒì•„ê°€ê³  ì‹¶ìœ¼ì‹œë©´ "ã…ã…‡"ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”! ğŸ‘ˆ'

   res = {
       "version": "2.0",
       "template": {
           "outputs": [
               {
                   "simpleText": {
                       "text": answer
                   }
               }
           ]
       }
   }

   return jsonify(res)


@app.route('/stock', methods=['POST']) # í•œêµ­ ì£¼ì‹ ì •ë³´ ë¸”ëŸ­ì— ìŠ¤í‚¬ë¡œ ì—°ê²°ëœ ê²½ë¡œ
def stock():

    req = request.get_json()
    company = req["action"]["detailParams"]["sys_text"]["value"]

    enc_com = urllib.parse.quote(company + '+ ì£¼ì‹')
    com = str(enc_com)
    url = 'https://m.search.naver.com/search.naver'
    url = url + '?sm=mtp_hty.top&where=m&query='
    url = url + com

    req = Request(url)
    page = urlopen(req)
    html = page.read()
    soup = BeautifulSoup(html, 'html.parser')
    temp = soup.find('div', class_='stock_price')
    temp_s = temp.find('strong', class_='price').text

    if 1 > 0:
        answer = company + "ì˜ í˜„ì¬ ê°€ê²©ì€ " + temp_s + "ì› ì…ë‹ˆë‹¤. ì„±íˆ¬ í•˜ì„¸ìš”!" + '\n' + '\n'
        answer += 'ì „ ë‹¨ê³„ë¡œ ëŒì•„ê°€ê³  ì‹¶ìœ¼ì‹œë©´ "ã…ã…‡"ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”! ğŸ‘ˆ'

    res = {
        "version": "2.0",
        "template": {
            "outputs": [
                {
                    "simpleText": {
                        "text": answer
                    }
                }
            ]
        }
    }

    return jsonify(res)

# ë©”ì¸ í•¨ìˆ˜
if __name__ == '__main__':

    app.run(host='0.0.0.0', port=5000, threaded=True)
